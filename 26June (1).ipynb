{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 1, stride=1, padding=0)\n",
    "        for j in range(3):\n",
    "            for i in range(6):\n",
    "                exec(\"self.Resconv1\"+str(j)+str(i)+\"=\"+\"nn.Conv2d(32, 32, 3, stride=1, padding=1)\")\n",
    "                exec(\"self.Batch_norm1\"+str(j)+str(i)+\"=\"+\"nn.BatchNorm2d(32, track_running_stats=False)\")\n",
    "                exec(\"self.Resconv2\"+str(j)+str(i)+\"=\"+\"nn.Conv2d(32, 32, 3, stride=1, padding=1)\")\n",
    "                exec(\"self.Batch_norm2\"+str(j)+str(i)+\"=\"+\"nn.BatchNorm2d(32, track_running_stats=False)\")\n",
    "#         self.Resconv1 = nn.Conv2d(32, 32, 3, stride=1, padding=1)\n",
    "#         self.Batch_norm1 = nn.BatchNorm2d(32)\n",
    "#         self.Resconv2 = nn.Conv2d(32, 32, 3, stride=1, padding=1)\n",
    "#         self.Batch_norm2 = nn.BatchNorm2d(32)\n",
    "        self.Transconv1 = nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding = 1)\n",
    "        self.Transconv2 = nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 3*256, 1, stride=1, padding=0)\n",
    "\n",
    "        self.Maskconv1 = nn.Conv2d(3, 64, 7, stride=1, padding=3)\n",
    "        for i in range(20):\n",
    "            exec(\"self.Gateconv1\"+str(i)+ \"=\"+ \"nn.Conv2d(64, 2*64, 5, stride=1, padding=2)\")\n",
    "            exec(\"self.Gateconv2\"+str(i)+ \"=\"+ \"nn.Conv2d(2*64, 2*64, (1,1), stride=1, padding=0)\")\n",
    "            exec(\"self.Gateconv3\"+str(i)+ \"=\"+ \"nn.Conv2d(64, 2*64, (1,5), stride=1, padding=(0,2))\")\n",
    "            exec(\"self.Gateconv4\"+str(i)+ \"=\"+ \"nn.Conv2d(64, 64, (1,1), stride=1, padding=0)\")\n",
    "        self.Maskconv2 = nn.Conv2d(64, 1024, 1, stride=1, padding=0)\n",
    "        self.Maskconv3 = nn.Conv2d(1024, 3*256, 1, stride=1, padding=0)\n",
    "\n",
    "#         self.conv1.weight = nn.Parameter(self.weight_init(3, 32, (1,1), mask_type = None))\n",
    "#         self.Resconv1.weight = nn.Parameter(self.weight_init(32, 32, (3,3), mask_type = None))\n",
    "#         self.Transconv1.weight = nn.Parameter(self.weight_init(32, 32, (3,3), mask_type = None))\n",
    "#         self.Resconv2.weight = nn.Parameter(self.weight_init(32, 32, (3,3), mask_type = None))\n",
    "#         self.Transconv2.weight = nn.Parameter(self.weight_init(32, 32, (3,3), mask_type = None))\n",
    "#         self.conv2.weight = nn.Parameter(self.weight_init(32, 3*256, (1,1), mask_type = None))\n",
    "\n",
    "        self.Maskconv1.weight = nn.Parameter(self.weight_init(3, 64, (7,7), mask_type='A'))\n",
    "        for i in range(20):\n",
    "            exec(\"self.Gateconv1\"+str(i)+\".weight\"+\"=\"+\"nn.Parameter(self.weight_init(64, 2*64, (5,5), mask_type='C'))\")\n",
    "            exec(\"self.Gateconv2\"+str(i)+\".weight\"+\"=\"+\"nn.Parameter(self.weight_init(2*64, 2*64, (1,1), mask_type=None))\")\n",
    "            exec(\"self.Gateconv3\"+str(i)+\".weight\"+\"=\"+ \"nn.Parameter(self.weight_init(64, 2*64, (1,5), mask_type='B'))\")\n",
    "            exec(\"self.Gateconv4\"+str(i)+\".weight\"+\"=\"+\"nn.Parameter(self.weight_init(64, 64, (1,1), mask_type='B'))\")\n",
    "        self.Maskconv2.weight = nn.Parameter(self.weight_init(64, 1024, (1,1), mask_type='B'))\n",
    "        self.Maskconv3.weight = nn.Parameter(self.weight_init(1024, 3*256, (1,1), mask_type='B'))\n",
    "\n",
    "    def weight_init(self, in_channel, num_outputs, kernel_shape, mask_type=None):\n",
    "        kernel_h, kernel_w = kernel_shape\n",
    "        center_h = kernel_h // 2\n",
    "        center_w = kernel_w // 2\n",
    "\n",
    "        mask = np.zeros((num_outputs, in_channel, kernel_h, kernel_w), dtype=np.float32)\n",
    "        if mask_type is not None:\n",
    "            mask[:, :, :center_h, :] = 1\n",
    "            if mask_type == 'A':\n",
    "                mask[:, :, center_h, :center_w] = 1\n",
    "            if mask_type == 'B':\n",
    "                mask[:, :, center_h, :center_w+1] = 1\n",
    "        else:\n",
    "            mask[:, :, :, :] = 1\n",
    "\n",
    "        weights_shape = [num_outputs, in_channel, kernel_h, kernel_w]\n",
    "        weights = torch.empty(weights_shape, requires_grad=True)\n",
    "        weights = nn.init.xavier_normal_(weights)\n",
    "        weights = weights*torch.from_numpy(mask)\n",
    "        return weights\n",
    "\n",
    "    def prior_network(self, hr_images):\n",
    "        conv1 = self.Maskconv1(hr_images)\n",
    "        inputs = conv1\n",
    "        state = conv1\n",
    "        for i in range(20):\n",
    "            inputs, state = self.gated_conv2d(inputs, state, [5, 5], i)\n",
    "        conv2 = self.Maskconv2(inputs)\n",
    "        conv2 = F.relu(conv2)\n",
    "        prior_logits = self.Maskconv3(conv2)\n",
    "        prior_logits = torch.cat((prior_logits[:, 0::3, :, :], prior_logits[:, 1::3, :, :], prior_logits[:, 2::3, :, :]), 1)\n",
    "        return prior_logits\n",
    "\n",
    "    def conditioning_network(self, lr_images):\n",
    "        res_num = 6\n",
    "        inputs = lr_images\n",
    "        inputs = self.conv1(inputs)\n",
    "        for i in range(2):\n",
    "            for j in range(res_num):\n",
    "                inputs = self.resnet_block(inputs, i, j)\n",
    "            inputs = eval(\"self.Transconv\"+str(i+1))(inputs)\n",
    "            inputs = F.relu(inputs)\n",
    "        for i in range(res_num):\n",
    "            inputs = self.resnet_block(inputs, 2, i)\n",
    "        conditioning_logits = self.conv2(inputs)\n",
    "        return conditioning_logits\n",
    "\n",
    "#     def batch_norm(self, x):\n",
    "#         bn = nn.BatchNorm2d(x.shape[1], affine=True, track_running_stats=True)\n",
    "#         return bn(x)\n",
    "\n",
    "    def resnet_block(self, inputs, i, j):\n",
    "        conv1 = eval(\"self.Resconv1\"+str(i)+str(j))(inputs)\n",
    "        bn1 = eval(\"self.Batch_norm1\"+str(i)+str(j))(conv1)\n",
    "        relu1 = F.relu(bn1)\n",
    "        conv2 = eval(\"self.Resconv2\"+str(i)+str(j))(relu1)\n",
    "        bn2 = eval(\"self.Batch_norm2\"+str(i)+str(j))(conv2)\n",
    "        output = inputs + bn2\n",
    "        return output\n",
    "\n",
    "\n",
    "    def gated_conv2d(self, inputs, state, kernel_shape, i):\n",
    "        batch_size, in_channel, height, width  = list(inputs.size())\n",
    "        kernel_h, kernel_w = kernel_shape\n",
    "        left = eval(\"self.Gateconv1\"+str(i))(state)\n",
    "        left1 = left[:, 0:in_channel, :, :]\n",
    "        left2 = left[:, in_channel:, :, :]\n",
    "        left1 = F.tanh(left1)\n",
    "        left2 = F.sigmoid(left2)\n",
    "        new_state = left1 * left2\n",
    "        left2right = eval(\"self.Gateconv2\"+str(i))(left)\n",
    "        right = eval(\"self.Gateconv3\"+str(i))(inputs)\n",
    "        right = right + left2right\n",
    "        right1 = right[:, 0:in_channel, :, :]\n",
    "        right2 = right[:, in_channel:, :, :]\n",
    "        right1 = F.tanh(right1)\n",
    "        right2 = F.sigmoid(right2)\n",
    "        up_right = right1 * right2\n",
    "        up_right = eval(\"self.Gateconv4\"+str(i))(up_right)\n",
    "        outputs = inputs + up_right\n",
    "        return outputs, new_state\n",
    "\n",
    "    def forward(self, lr_images, hr_images):\n",
    "        hr_images = hr_images - 0.5\n",
    "        lr_images = lr_images - 0.5\n",
    "        prior_logits = self.prior_network(hr_images)\n",
    "        conditioning_logits = self.conditioning_network(lr_images)\n",
    "        return prior_logits, conditioning_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(logits, labels):\n",
    "    logits = logits.permute(0, 2, 3, 1)\n",
    "    logits = torch.reshape(logits, [-1, 256])\n",
    "    labels = labels.to(torch.int64)\n",
    "    labels = labels.permute(0, 2, 3, 1)\n",
    "    labels = torch.reshape(labels, [-1])\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "def train(model, device, train_loader_lr, train_loader_hr, optimizer, epoch):\n",
    "    model.train()\n",
    "    for (batch_idx, (data, t)), (target, p) in zip(enumerate(train_loader_lr), train_loader_hr):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        prior_logits, conditioning_logits = model(lr_images = torch.floor(data*255), hr_images = torch.floor(target*255))\n",
    "        l1 = softmax_loss(prior_logits+conditioning_logits, torch.floor(target*255))\n",
    "        l2 = softmax_loss(conditioning_logits, torch.floor(target*255))\n",
    "        loss = l1+l2\n",
    "        loss3 = softmax_loss(prior_logits, torch.floor(target*255))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), (len(train_loader_lr)*len(data)),\n",
    "                100. * batch_idx / len(train_loader_lr), loss.item()))\n",
    "\n",
    "        if batch_idx % 10 == 0 and batch_idx != 0:\n",
    "#             print(list(model.Gateconv415.parameters()))\n",
    "            sample(model, data, target, len(data), mu=1.1, step=epoch*batch_idx)\n",
    "\n",
    "\n",
    "\n",
    "def test(model, device, test_loader_lr, test_loader_hr):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (data, t), (target, p) in zip(test_loader_lr, test_loader_hr):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            prior_logits, conditioning_logits = model(lr_images = torch.floor(data*255), hr_images = torch.floor(target*255))\n",
    "            l1 = softmax_loss(prior_logits+conditioning_logits, torch.floor(target*255))\n",
    "            l2 = softmax_loss(conditioning_logits, torch.floor(target*255))\n",
    "            test_loss += l1+l2 # sum up batch loss\n",
    "\n",
    "    test_loss /= len(test_loader_lr)*32\n",
    "    print(\"test_loss : \", test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_2_pixel_value(logits, mu=1.1):\n",
    "    # print(\"convert\")\n",
    "#     print(\"logits\", logits)\n",
    "    rebalance_logits = logits * mu\n",
    "    probs = softmax(rebalance_logits)\n",
    "    pixel_dict = torch.arange(0, 256, dtype=torch.float32)\n",
    "    pixels = torch.sum(probs*pixel_dict, dim=1)\n",
    "    return pixels/255\n",
    "\n",
    "def softmax(x):\n",
    "    # print(\"cal\")\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # x = x.detach().numpy()\n",
    "    a, b = torch.max(x, -1, keepdim=True, out=None)\n",
    "    e_x = torch.exp(x - a)\n",
    "    return e_x / e_x.sum(dim=-1, keepdim =True) # only difference\n",
    "\n",
    "def sample(model, data, target, batch_size, mu=1.1, step=None):\n",
    "    with torch.no_grad():\n",
    "        np_lr_imgs = data\n",
    "        np_hr_imgs = target\n",
    "        c_logits = model.conditioning_network\n",
    "        p_logits = model.prior_network\n",
    "        gen_hr_imgs = torch.zeros((batch_size, 3, 32, 32), dtype=torch.float32)\n",
    "        np_c_logits = c_logits(torch.floor(np_lr_imgs*255))\n",
    "        print(\"torch.floor(np_lr_imgs*255)\", torch.floor(np_lr_imgs*255)[0][:,0,0])\n",
    "        print(\"c_logits\", np_c_logits[0].shape, torch.max(np_c_logits[0][:,0,0], -1))\n",
    "        print(\"p_logits\", p_logits(gen_hr_imgs)[0].shape, p_logits(gen_hr_imgs)[0][:,0,0])\n",
    "        print(\"target\", torch.floor(target*255)[0][:,0,0])\n",
    "        for i in range(32):\n",
    "            print(i)\n",
    "            for j in range(32):\n",
    "                for c in range(3):\n",
    "#                     print(i,j,c)\n",
    "                    np_p_logits = p_logits(gen_hr_imgs)\n",
    "                    new_pixel = logits_2_pixel_value(np_c_logits[:, c*256:(c+1)*256, i, j] + np_p_logits[:, c*256:(c+1)*256, i, j], mu=mu)\n",
    "                    gen_hr_imgs[:, c, i, j] = new_pixel\n",
    "                    # try:\n",
    "                    # \tfor obj in gc.get_objects():\n",
    "                    # \t\tif torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                    # \t\t\tprint(type(obj), obj.size())\n",
    "                    # except:\n",
    "                    # \tprint(\"error\")\n",
    "        samples_dir = \"/home/eee/ug/15084005/DIH/samples/\"\n",
    "        print(\"sample\")\n",
    "        save_samples(np_lr_imgs, samples_dir + '/lr_' + str(mu*10) + '_' + str(step))\n",
    "        save_samples(np_hr_imgs, samples_dir + '/hr_' + str(mu*10) + '_' + str(step))\n",
    "        save_samples(gen_hr_imgs, samples_dir + '/generate_' + str(mu*10) + '_' + str(step))\n",
    "\n",
    "def save_samples(np_imgs, img_path):\n",
    "    print(\"save\")\n",
    "    torchvision.utils.save_image(np_imgs[0, :, :, :], img_path+\".jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--use_gpu\", type = bool, default = True, help = \"use or not gpu\")\n",
    "#     parser.add_argument(\"--num_epoch\", type = int, default = 30, help = \"no of epoch\")\n",
    "#     parser.add_argument(\"--batch_size\", type = int, default = 32, help = \"batch size\")\n",
    "#     parser.add_argument(\"--learning_rate\", type = float, default = 4e-4, help = \"learning rate\")\n",
    "#     args = parser.parse_args()\n",
    "    use_gpu = False\n",
    "    num_epoch = 30\n",
    "    batch_size = 32\n",
    "    learning_rate = 4e-4\n",
    "\n",
    "    use_cuda = use_gpu and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#     torch.cuda.set_device(0)\n",
    "\n",
    "    data = datasets.ImageFolder(root = '/home/eee/ug/15084005/DIH/CelebA/CelebA/train/', transform = transforms.Compose([transforms.Resize((8,8), interpolation=2), transforms.ToTensor()]))\n",
    "    target = datasets.ImageFolder(root = '/home/eee/ug/15084005/DIH/CelebA/CelebA/train/', transform = transforms.Compose([transforms.Resize((32,32), interpolation=2), transforms.ToTensor()]))\n",
    "\n",
    "    data_test = datasets.ImageFolder(root = '/home/eee/ug/15084005/DIH/CelebA/CelebA/test/', transform = transforms.Compose([transforms.Resize((8,8), interpolation=2), transforms.ToTensor()]))\n",
    "    target_test = datasets.ImageFolder(root = '/home/eee/ug/15084005/DIH/CelebA/CelebA/test/', transform = transforms.Compose([transforms.Resize((32,32), interpolation=2), transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "    #test_split = .05\n",
    "    #shuffle_dataset = True\n",
    "    #random_seed= 42\n",
    "    # Creating data indices for training and validation splits:\n",
    "    # dataset_size = len(image_data_hr)\n",
    "    # indices = list(range(dataset_size))\n",
    "    # split = int(np.floor(test_split * dataset_size))\n",
    "    # if shuffle_dataset :\n",
    "    # \tnp.random.seed(random_seed)\n",
    "    # \tnp.random.shuffle(indices)\n",
    "    # train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # data = [image_data_lr[x] for x in train_indices]\n",
    "    # target = [image_data_hr[x] for x in train_indices]\n",
    "\n",
    "    # data_test = [image_data_lr[x] for x in train_indices]\n",
    "    # target_test = [image_data_hr[x] for x in train_indices]\n",
    "\n",
    "    train_sampler_lr = torch.utils.data.sampler.SequentialSampler(data)\n",
    "    train_sampler_hr = torch.utils.data.sampler.SequentialSampler(target)\n",
    "\n",
    "    test_sampler_lr = torch.utils.data.sampler.SequentialSampler(data_test)\n",
    "    test_sampler_hr = torch.utils.data.sampler.SequentialSampler(target_test)\n",
    "\n",
    "    train_loader_lr = torch.utils.data.DataLoader(data, batch_size=batch_size, sampler=train_sampler_lr)\n",
    "    train_loader_hr = torch.utils.data.DataLoader(target, batch_size=batch_size, sampler=train_sampler_hr)\n",
    "\n",
    "    test_loader_lr = torch.utils.data.DataLoader(data_test, batch_size=batch_size, sampler=test_sampler_lr)\n",
    "    test_loader_hr = torch.utils.data.DataLoader(target_test, batch_size=batch_size, sampler=test_sampler_hr)\n",
    "\n",
    "    model = Net()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.95)\n",
    "    print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "#     for parameter in model.parameters():\n",
    "#         print(parameter)\n",
    "#     print(list(model.Maskconv1.parameters()))\n",
    "#     print(list(model.Gateconv415.parameters()))\n",
    "    for epoch in range(1, num_epoch+1):\n",
    "        train(model, device, train_loader_lr, train_loader_hr, optimizer, epoch)\n",
    "        # sample(model, train_loader_lr, train_loader_hr, mu=1.1, step=epoch)\n",
    "        test(model, device, test_loader_lr, test_loader_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6576192\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
