{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 1, stride=1, padding=0)\n",
    "        for j in range(3):\n",
    "            for i in range(6):\n",
    "                exec(\"self.Resconv1\"+str(j)+str(i)+\"=\"+\"nn.Conv2d(32, 32, 3, stride=1, padding=1)\")\n",
    "                exec(\"self.Batch_norm1\"+str(j)+str(i)+\"=\"+\"nn.BatchNorm2d(32, track_running_stats=False)\")\n",
    "                exec(\"self.Resconv2\"+str(j)+str(i)+\"=\"+\"nn.Conv2d(32, 32, 3, stride=1, padding=1)\")\n",
    "                exec(\"self.Batch_norm2\"+str(j)+str(i)+\"=\"+\"nn.BatchNorm2d(32, track_running_stats=False)\")\n",
    "        self.Transconv1 = nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding = 1)\n",
    "        self.Transconv2 = nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 3*256, 1, stride=1, padding=0)\n",
    "\n",
    "    def conditioning_network(self, lr_images):\n",
    "        res_num = 6\n",
    "        inputs = lr_images\n",
    "        inputs = self.conv1(inputs)\n",
    "        for i in range(2):\n",
    "            for j in range(res_num):\n",
    "                inputs = self.resnet_block(inputs, i, j)\n",
    "            inputs = eval(\"self.Transconv\"+str(i+1))(inputs)\n",
    "            inputs = F.relu(inputs)\n",
    "        for i in range(res_num):\n",
    "            inputs = self.resnet_block(inputs, 2, i)\n",
    "        conditioning_logits = self.conv2(inputs)\n",
    "        return conditioning_logits\n",
    "\n",
    "    def resnet_block(self, inputs, i, j):\n",
    "        conv1 = eval(\"self.Resconv1\"+str(i)+str(j))(inputs)\n",
    "        bn1 = eval(\"self.Batch_norm1\"+str(i)+str(j))(conv1)\n",
    "        relu1 = F.relu(bn1)\n",
    "        conv2 = eval(\"self.Resconv2\"+str(i)+str(j))(relu1)\n",
    "        bn2 = eval(\"self.Batch_norm2\"+str(i)+str(j))(conv2)\n",
    "        output = inputs + bn2\n",
    "        return output\n",
    "\n",
    "    def forward(self, lr_images):\n",
    "        lr_images = lr_images - 0.5\n",
    "        conditioning_logits = self.conditioning_network(lr_images)\n",
    "        return conditioning_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(logits, labels):\n",
    "    logits = logits.permute(0, 2, 3, 1)\n",
    "    logits = torch.reshape(logits, [-1, 256])\n",
    "    labels = labels.to(torch.int64)\n",
    "    labels = labels.permute(0, 2, 3, 1)\n",
    "    labels = torch.reshape(labels, [-1])\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "def test(args, model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader,1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            conditioning_logits = model(lr_images = data)\n",
    "            l2 = softmax_loss(conditioning_logits, torch.floor(target*255))\n",
    "            test_loss += l2 # sum up batch loss\n",
    "    test_loss /= len(test_loader)*len(data)\n",
    "    print(\"test_loss : \", test_loss.item())\n",
    "    sample(model, data, target, len(data), mu=1.1, step=epoch)\n",
    "\n",
    "def logits_2_pixel_value(logits, mu=1.1):\n",
    "    rebalance_logits = logits * mu\n",
    "    probs = softmax(rebalance_logits)\n",
    "    pixel_dict = torch.arange(0, 256, dtype=torch.float32)\n",
    "    pixels = torch.sum(probs*pixel_dict, dim=1)\n",
    "    return (pixels/255)\n",
    "\n",
    "def softmax(x):\n",
    "    a, b = torch.max(x, -1, keepdim=True, out=None)\n",
    "    e_x = torch.exp(x - a)\n",
    "    return e_x / e_x.sum(dim=-1, keepdim =True) # only difference\n",
    "\n",
    "def sample(model, data, target, batch_size, mu=1.1, step=None):\n",
    "    with torch.no_grad():\n",
    "        np_lr_imgs = data\n",
    "        np_hr_imgs = target\n",
    "        c_logits = model.conditioning_network\n",
    "        #p_logits = model.prior_network\n",
    "        gen_hr_imgs = torch.zeros((batch_size, 3, 32, 32), dtype=torch.float32)\n",
    "        np_c_logits = c_logits(np_lr_imgs)\n",
    "        for i in range(32):\n",
    "            for j in range(32):\n",
    "                for c in range(3):\n",
    "                    new_pixel = logits_2_pixel_value(np_c_logits[:, c*256:(c+1)*256, i, j], mu=mu)\n",
    "                    gen_hr_imgs[:, c, i, j] = new_pixel\n",
    "        samples_dir =  \"/home/eee/ug/15084005/DIH/samples_ip/\"\n",
    "        print(\"sample\")\n",
    "        save_samples(np_lr_imgs, samples_dir + '/lr_' + str(mu*10) + '_' + str(step))\n",
    "        save_samples(np_hr_imgs, samples_dir + '/hr_' + str(mu*10) + '_' + str(step))\n",
    "        save_samples(gen_hr_imgs, samples_dir + '/generate_' + str(mu*10) + '_' + str(step))\n",
    "\n",
    "def save_samples(np_imgs, img_path):\n",
    "    print(\"save\")\n",
    "    torchvision.utils.save_image(np_imgs[0, :, :, :], img_path+\".jpg\")\n",
    "\n",
    "def load_image( infilename ) :\n",
    "    img = Image.open( infilename )\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"float32\" )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.to(\"cpu\")\n",
    "model.load_state_dict(torch.load(\"/home/eee/ug/15084005/DIH/models/30.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target  = torchvision.transforms.ToTensor()\n",
    "target = target(load_image(\"d3_32*32.png\"))\n",
    "target = target.unsqueeze_(0)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = torchvision.transforms.ToTensor()\n",
    "data = data(load_image(\"d3_8*8.png\"))\n",
    "data = data.unsqueeze_(0)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n",
      "save\n",
      "save\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sample(model, data, target, batch_size=1, mu=1.1, step=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
